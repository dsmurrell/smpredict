library(mclust)
library(multicore)
library(kernlab)
library(caret)
library(dsmR)
library(ggplot2)
library(gbm)
library(matie)
load("PKKB.rda")
d <- read.csv("../PKKB/1D_logp.csv")
d <- data.frame(ID=d$Name, logp=d$LogP, tetra=d$Tetravalent)
d <- d[which(d$tetra=='False'),]
badIndexes <- c(which(d$ID == "Diltiazem"), which(d$ID == "Verapamil")) # these two structures were incorrect in the data but were also in the training set so they get removed here
d <- d[-badIndexes, ]
dh(d)
logp_PKKB <- d$logP
logp_PKKB
logp_PKKB <- d$logp
logp_PKKB
d <- read.csv("../Martel/4D_logp.csv")
descriptors <- read.csv("../Martel/smLogP/descriptors.csv")
d <- read.csv("../Martel/4D_logp.csv")
dh(d)
logp_Martel <- d$logPexp
load("../../ensembles/data.rda")
load("../ensembles/data.rda")
load("../../5_ensembles_all/data.rda")
density <- data.frame(LogP = c(), Dataset=c())
density <- rbind(density, data.frame(LogP = y.train, Dataset = rep("Hold out test set", length(y.train))))
density <- rbind(density, data.frame(LogP = logp_PKKB, Dataset = rep("PKKB", length(logp_PKKB))))
density <- rbind(density, data.frame(LogP = logp_Martel, Dataset = rep("Martel", length(logp_Martel))))
pdf("logP_distributions.pdf")
ggplot(density, aes(x=LogP, fill=Dataset)) + geom_density(alpha=.3) + ylab("Density") +
theme(legend.justification=c(1,1), legend.position=c(1,1)) +
scale_fill_manual(values = c("#99AA33", "#993333", "#9933AA"))
dev.off()
# density plot
density <- data.frame(LogP = c(), Dataset=c())
density <- rbind(density, data.frame(LogP = y.train, Dataset = rep("BioByte Star Set", length(y.train))))
density <- rbind(density, data.frame(LogP = logp_PKKB, Dataset = rep("PKKB", length(logp_PKKB))))
density <- rbind(density, data.frame(LogP = logp_Martel, Dataset = rep("Martel", length(logp_Martel))))
pdf("logP_distributions.pdf")
ggplot(density, aes(x=LogP, fill=Dataset)) + geom_density(alpha=.3) + ylab("Density") +
theme(legend.justification=c(1,1), legend.position=c(1,1)) +
scale_fill_manual(values = c("#99AA33", "#993333", "#9933AA"))
dev.off()
# density plot
density <- data.frame(LogP = c(), Dataset=c())
density <- rbind(density, data.frame(LogP = y.train, Dataset = rep("BioByte Star Set", length(y.train))))
density <- rbind(density, data.frame(LogP = logp_PKKB, Dataset = rep("PKKB Test Set", length(logp_PKKB))))
density <- rbind(density, data.frame(LogP = logp_Martel, Dataset = rep("Martel Test Set", length(logp_Martel))))
pdf("logP_distributions.pdf")
ggplot(density, aes(x=LogP, fill=Dataset)) + geom_density(alpha=.3) + ylab("Density") +
theme(legend.justification=c(1,1), legend.position=c(1,1)) +
scale_fill_manual(values = c("#99AA33", "#993333", "#9933AA"))
dev.off()
# DENSITY PLOTTING
# density plot
density <- data.frame(LogP = c(), Dataset=c())
density <- rbind(density, data.frame(LogP = y.train, Dataset = rep("BioByte Star Set", length(y.train))))
density <- rbind(density, data.frame(LogP = logp_PKKB, Dataset = rep("PKKB Set", length(logp_PKKB))))
density <- rbind(density, data.frame(LogP = logp_Martel, Dataset = rep("Martel Set", length(logp_Martel))))
pdf("logP_distributions.pdf")
ggplot(density, aes(x=LogP, fill=Dataset)) + geom_density(alpha=.3) + ylab("Density") +
theme(legend.justification=c(1,1), legend.position=c(1,1)) +
scale_fill_manual(values = c("#99AA33", "#993333", "#9933AA"))
dev.off()
density <- data.frame(LogP = c(), Dataset=c())
density <- rbind(density, data.frame(LogP = y.train, Dataset = rep("BioByte Star Set", length(y.train))))
density <- rbind(density, data.frame(LogP = logp_PKKB, Dataset = rep("PKKB Set", length(logp_PKKB))))
density <- rbind(density, data.frame(LogP = logp_Martel, Dataset = rep("Martel Set", length(logp_Martel))))
pdf("logP_distributions.pdf")
theme_set(theme_bw(14))
ggplot(density, aes(x=LogP, fill=Dataset)) + geom_density(alpha=.3) + ylab("Density") +
theme(legend.justification=c(1,1), legend.position=c(1,1)) +
scale_fill_manual(values = c("#99AA33", "#993333", "#9933AA"))
dev.off()
setwd("~/Dropbox/Shared/Toxicogenetics")
t <- read.table("ToxChallenge_CytotoxicityData_Train.txt")
dim(t)
dh(t)
s <- read.table("ToxChallenge_CytotoxicitySummaryStatistics_Train_Subchal2.txt")
dh(s)
dh(t)
dh(s)
d <- read.table("Genotypes/ToxChallenge_genotype_dosage_chr11.txt")
dh(d)
setwd("~/Dropbox/projects/logP/6_comparison_to_other_tools/Martel")
library(dsmR)
library(smPredict)
# assign an estimated logP average value of 2.5 to the ones that didn't get through any prediction tool
results <- list()
#### Martel data
d <- read.csv("4D_logp.csv")
d <- data.frame(ID=d$ID, smiles=d$SMILES, logp=d$logPexp)
dh(d)
#### SMLOGP
load("smLogP/smlogp.rda")
smlogp <- data.frame(ID=smlogp$ID, smlogp=smlogp$smLogP)
dh(smlogp)
m <- merge(d, smlogp, all.x = TRUE)
dh(m)
results$smlogp <- RMSE(m$logp, m$smlogp)
AM <- mean(m$logp)
m$smlogp[which(is.na(m$smlogp))] <- AM
#### HIGH
# load("high/high.rda")
# smlogp <- data.frame(ID=high$ID, high=high$smLogP)
# dh(high)
# m <- merge(d, high, all.x = TRUE)
# dh(m)
# results$high <- RMSE(m$logp, m$high)
# m$high[which(is.na(m$high))] <- AM
#### ALOGPS
alogps <- read.csv("ALogPS/AlogPS_results.csv")
alogps <- data.frame(smiles=alogps$X, alogps=alogps$logP)
dh(alogps)
m <- merge(m, alogps, all.x = TRUE)
m$alogps[which(is.na(m$alogps))] <- AM
dh(m)
results$alogps <- RMSE(m$logp, m$alogps)
#### CLOGP
clogp <- read.csv("clogp/clogp.csv", header=FALSE)
dh(clogp)
clogp <- data.frame(ID=clogp$V4, clogp=clogp$V1)
dh(clogp)
m <- merge(m, clogp, all.x = TRUE)
m$clogp[which(is.na(m$clogp))] <- AM
dh(m)
plot(m$logp, m$clogp)
results$clogp <- RMSE(m$logp, m$clogp)
#### MILOGP
milogp <- read.csv("milogp/milogp.csv", header=TRUE)
dh(milogp)
milogp <- data.frame(ID=milogp$ID, milogp=milogp$milogp)
dh(milogp)
m <- merge(m, milogp, all.x = TRUE)
m$milogp[which(is.na(m$milogp))] <- AM
dh(m)
plot(m$logp, m$milogp)
results$milogp <- RMSE(m$logp, m$milogp)
#### XLOGP3
xlogp3 <- read.csv("xlogp3/xlogp3.csv")
xlogp3 <- data.frame(ID=xlogp3$ID, xlogp3=xlogp3$xlogp3)
dh(xlogp3)
m <- merge(m, xlogp3, all.x = TRUE)
m$xlogp3[which(is.na(m$xlogp3))] <- AM
dh(m)
results$xlogp3 <- RMSE(m$logp, m$xlogp3)
# can get a better prediction using an average of my model and xlogp3
#results$xlogp3andme <- RMSE(m$logp, 0.5*m$xlogp3 + 0.5*m$smlogp)
#### LEO (alogp, mlogp, spluslogp)
leo <- read.csv("leo/leo.csv")
leo <- data.frame(ID=leo$Name, alogp=leo$alogp, mlogp=leo$mlogp, spluslogp=leo$spluslogp)
dh(leo)
m <- merge(m, leo, all.x = TRUE)
m$alogp[which(is.na(m$alogp))] <- AM
m$mlogp[which(is.na(m$mlogp))] <- AM
m$spluslogp[which(is.na(m$spluslogp))] <- AM
dh(m)
results$alogp <- RMSE(m$logp, m$alogp)
results$mlogp <- RMSE(m$logp, m$mlogp)
results$spluslogp <- RMSE(m$logp, m$spluslogp)
#### PaDEL logPs
load("smlogp/descriptors.rda")
padel = data.frame(ID=descriptors$Name,
p.xlogp = descriptors$XLogP,
p.mlogp = descriptors$MLogP,
p.alogp = descriptors$ALogP,
p.crippen = descriptors$CrippenLogP)
dh(padel)
m <- merge(m, padel, all.x = TRUE)
m$p.xlogp[which(is.na(m$p.xlogp))] <- AM
m$p.mlogp[which(is.na(m$p.mlogp))] <- AM
m$p.alogp[which(is.na(m$p.alogp))] <- AM
m$p.alogp[which(is.na(m$p.crippen))] <- AM
dh(m)
results$p.xlogp <- RMSE(m$logp, m$p.xlogp)
results$p.mlogp <- RMSE(m$logp, m$p.mlogp)
results$p.alogp <- RMSE(m$logp, m$p.alogp)
results$p.crippen <- RMSE(m$logp, m$p.crippen)
#### AM
m$am <- rep(mean(m$logp, nrow(m)))
results$am <- RMSE(m$logp, m$am)
r <- sort(sapply(results, function(x) x))
results
plot(m$logp, m$milogp)
abline(0,1)
points(m$logp, m$smlogp, col="red")
library(png)
library(mclust)
library(multicore)
library(kernlab)
library(caret)
library(dsmR)
library(ggplot2)
library(gbm)
library(matie)
source("functions.R")
AM <- 2.5
load("../../5_ensembles_all/data.rda")
#### PKKB data, predict and plot
d <- read.csv("../PKKB/1D_logp.csv")
d <- data.frame(ID=d$Name, logp=d$LogP, tetra=d$Tetravalent)
d <- d[which(d$tetra=='False'),]
badIndexes <- c(which(d$ID == "Diltiazem"), which(d$ID == "Verapamil")) # these two structures were incorrect in the data but were also in the training set so they get removed here
d <- d[-badIndexes, ]
load("../PKKB/smLogP/smlogp.rda")
smlogp <- data.frame(ID=smlogp$ID, smlogp=smlogp$smLogP)
m <- merge(d, smlogp)
m$smlogp[which(is.na(m$smlogp))] <- AM
plot(m$smlogp, m$logp)
abline(0,1)
errors <- m$smlogp - m$logp
#### PKKB descriptors, merge and find distances
load("../PKKB/smLogP/descriptors.rda")
m <- merge(m, descriptors, by.x='ID', by.y='Name', all.x)
transformed <- predict(transformation, m[,names(x.train)])
#### Association Weightings
Ame <- function(x, y) {
ma(cbind(x,y))$A
}
#sample <- sample(1:nrow(x.train), 2000, replace=FALSE)
#as <- apply(x.train[sample, ], 2, Ame, y.train[sample])
#save(as, file="as.rda")
load("as.rda")
getSpearman <- function(p, n) {
outset <- transformed
for(i in 1:length(as)) {
outset[,i] <- outset[,i] * (as[i]^p)
}
inset <- x.train
for(i in 1:length(as)) {
inset[,i] <- inset[,i] * (as[i]^p)
}
distances <- findMinDistances(outset, inset, n)
sf <- 15/mean(distances)
distances <- distances*sf
ED <- data.frame(error = m$smlogp - m$logp, distance = distances)
ED_reverse <- data.frame(error = m$logp - m$smlogp, distance = distances)
EDC <- rbind(ED, ED_reverse)
distances <- seq(from=min(EDC$distance), to=max(EDC$distance), length.out=200)
sigmas <- getSigmaMatrix(errors=EDC$error, distances=distances, real_distances = EDC$distance, window_width=2, window_threshold=20)
q <- cbind(distances, sigmas)
q <- q[-which(sigmas==0),]
r <- list()
r$correlation <- cor(q,method='spearman')[2]
r$distances <- distances
r$q <- q
r
}
getDvSPlot <- function(r, fitSpline = FALSE) {
q <- as.data.frame(r$q)
p <- ggplot(q, aes(x=distances, y=sigmas))
p <- p + geom_point(size = 3, alpha = 1, col="black")
p <- p + xlab("Distance to training set") + ylab("Variance Estimate")
p <- p + theme(legend.justification=c(1,0), legend.position=c(1,0))
theme_set(theme_bw(14))
if(fitSpline) {
x <- q[,1]
y <- q[,2]
smoothingSpline = smooth.spline(x, y, spar=0.75)
spline <- data.frame(x=smoothingSpline$x, y=smoothingSpline$y)
p <- p + geom_line(data=spline, aes(x=x, y=y) , col="darkred")
}
p
}
s <- getSpearman(1.5, 5)
load("as.rda")
setwd("~/Dropbox/projects/logP/6_comparison_to_other_tools/error_estimation")
library(png)
library(mclust)
library(multicore)
library(kernlab)
library(caret)
library(dsmR)
library(ggplot2)
library(gbm)
library(matie)
source("functions.R")
AM <- 2.5
load("../../5_ensembles_all/data.rda")
#### PKKB data, predict and plot
d <- read.csv("../PKKB/1D_logp.csv")
d <- data.frame(ID=d$Name, logp=d$LogP, tetra=d$Tetravalent)
d <- d[which(d$tetra=='False'),]
badIndexes <- c(which(d$ID == "Diltiazem"), which(d$ID == "Verapamil")) # these two structures were incorrect in the data but were also in the training set so they get removed here
d <- d[-badIndexes, ]
load("../PKKB/smLogP/smlogp.rda")
smlogp <- data.frame(ID=smlogp$ID, smlogp=smlogp$smLogP)
m <- merge(d, smlogp)
m$smlogp[which(is.na(m$smlogp))] <- AM
plot(m$smlogp, m$logp)
abline(0,1)
errors <- m$smlogp - m$logp
#### PKKB descriptors, merge and find distances
load("../PKKB/smLogP/descriptors.rda")
m <- merge(m, descriptors, by.x='ID', by.y='Name', all.x)
transformed <- predict(transformation, m[,names(x.train)])
#### Association Weightings
Ame <- function(x, y) {
ma(cbind(x,y))$A
}
#sample <- sample(1:nrow(x.train), 2000, replace=FALSE)
#as <- apply(x.train[sample, ], 2, Ame, y.train[sample])
#save(as, file="as.rda")
load("as.rda")
getSpearman <- function(p, n) {
outset <- transformed
for(i in 1:length(as)) {
outset[,i] <- outset[,i] * (as[i]^p)
}
inset <- x.train
for(i in 1:length(as)) {
inset[,i] <- inset[,i] * (as[i]^p)
}
distances <- findMinDistances(outset, inset, n)
sf <- 15/mean(distances)
distances <- distances*sf
ED <- data.frame(error = m$smlogp - m$logp, distance = distances)
ED_reverse <- data.frame(error = m$logp - m$smlogp, distance = distances)
EDC <- rbind(ED, ED_reverse)
distances <- seq(from=min(EDC$distance), to=max(EDC$distance), length.out=200)
sigmas <- getSigmaMatrix(errors=EDC$error, distances=distances, real_distances = EDC$distance, window_width=2, window_threshold=20)
q <- cbind(distances, sigmas)
q <- q[-which(sigmas==0),]
r <- list()
r$correlation <- cor(q,method='spearman')[2]
r$distances <- distances
r$q <- q
r
}
getDvSPlot <- function(r, fitSpline = FALSE) {
q <- as.data.frame(r$q)
p <- ggplot(q, aes(x=distances, y=sigmas))
p <- p + geom_point(size = 3, alpha = 1, col="black")
p <- p + xlab("Distance to training set") + ylab("Variance Estimate")
p <- p + theme(legend.justification=c(1,0), legend.position=c(1,0))
theme_set(theme_bw(14))
if(fitSpline) {
x <- q[,1]
y <- q[,2]
smoothingSpline = smooth.spline(x, y, spar=0.75)
spline <- data.frame(x=smoothingSpline$x, y=smoothingSpline$y)
p <- p + geom_line(data=spline, aes(x=x, y=y) , col="darkred")
}
p
}
s <- getSpearman(1.5, 5)
s$correlation
p_15_5 <- getDvSPlot(s, fitSpline=TRUE)
print(p_15_5)
r <- s
q <- as.data.frame(r$q)
x <- q[,1]
y <- q[,2]
smoothingSpline = smooth.spline(x, y, spar=0.75)
spline <- data.frame(x=smoothingSpline$x, y=smoothingSpline$y)
spline
getDvSPlot <- function(r, fitSpline = FALSE) {
q <- as.data.frame(r$q)
p <- ggplot(q, aes(x=distances, y=sigmas))
p <- p + geom_point(size = 3, alpha = 1, col="black")
p <- p + xlab("Distance to training set") + ylab("Variance Estimate")
p <- p + theme(legend.justification=c(1,0), legend.position=c(1,0))
theme_set(theme_bw(14))
if(fitSpline) {
x <- q[,1]
y <- q[,2]
smoothingSpline = smooth.spline(x, y, spar=0.75)
spline <- data.frame(distance=smoothingSpline$x, variance=smoothingSpline$y)
p <- p + geom_line(data=spline, aes(x=distance, y=variance) , col="darkred")
}
p
}
p_15_5 <- getDvSPlot(s, fitSpline=TRUE)
print(p_15_5)
q <- as.data.frame(r$q)
x <- q[,1]
y <- q[,2]
smoothingSpline = smooth.spline(x, y, spar=0.75)
spline <- data.frame(distance=smoothingSpline$x, variance=smoothingSpline$y)
spline
smoothingSpline
?smooth.spline
predict(spline, 5)
predict(smoothingSpline, 5)
spline <- smoothingSpline
save(spline, file="spline.rda")
detach(package:smPredict, unload=TRUE)
library(smPredict)
PredictLogPFromDescriptors <- function(descriptors, error.variance=FALSE) {
print("Predicting LogP")
load(file = system.file("extdata", "data.rda", package="smPredict"))
load(file = system.file("extdata", "svm.rda", package="smPredict"))
load(file = system.file("extdata", "gbm.rda", package="smPredict"))
names <- descriptors[, 1]
used.descriptors <- names(x.train)
descriptors <- descriptors[, used.descriptors]
suppressWarnings(descriptors <- apply(descriptors, 2, as.numeric))
nrows <- nrow(descriptors)
to.impute <- rbind(descriptors, x.train)
set.seed(777)
imputed <- as.data.frame(impute.knn(as.matrix(to.impute), k = 10)$data)
to.predict <- imputed[1:nrows, ]
x <- predict(transformation, to.predict)
variances <- rep(NA, rnow(x))
if(error.variance) {
n <- 5
p <- 1.5
load(file = system.file("extdata", "spline.rda", package="smPredict"))
load(file = system.file("extdata", "as.rda", package="smPredict"))
outset <- to.predict
for(i in 1:length(as)) {
outset[,i] <- outset[,i] * (as[i]^p)
}
inset <- x.train
for(i in 1:length(as)) {
inset[,i] <- inset[,i] * (as[i]^p)
}
distances <- findMinDistances(outset, inset, n)
variances <- predict(spline, distances)
}
svm_pred <- predict(svm$finalModel, newdata = x)
gbm_pred <- predict(gbm$finalModel, newdata = x, n.trees = 500)
greedy_pred <- svm_pred*0.712 + gbm_pred*0.288
data.frame(ID = names, smLogP = greedy_pred)
}
PredictLogPFromDescriptorsFile <- function(descriptors.file, error.variance=FALSE) {
descriptors <- read.csv(file = descriptors.file)
PredictLogPFromDescriptors(descriptors, error.variance)
}
PredictLogP <- function(structures.file, error.variance=FALSE, threads = -1) {
standardised.file <- tempfile("standardised", fileext=".sdf")
name.file <- tempfile("name", fileext=".txt") # used to recover the original ordering of molecules (multicore descriptor generation messes this up)
descriptors.file <- tempfile("descriptors", fileext=".csv")
StandardiseMolecules(structures.file, standardised.file, name.file = name.file, limit = -1)
GenerateDescriptors.internal(standardised.file, descriptors.file, name.file, threads)
PredictLogPFromDescriptorsFile(descriptors.file, error.variance)
}
system.time(predictions <- PredictLogP(structures.file="structures.sdf", threads = 1))
setwd("~/Dropbox/projects/smPredict/testing_package")
system.time(predictions <- PredictLogP(structures.file="structures.sdf", threads = 1))
library(smPredict)
system.time(predictions <- PredictLogP(structures.file="structures.sdf", threads = 1))
detach(package:smPredict, unload=TRUE)
library(smPredict)
detach(package:smPredict, unload=TRUE)
library(smPredict)
system.time(predictions <- PredictLogP(structures.file="structures.sdf", threads = 1))
detach(package:smPredict, unload=TRUE)
library(smPredict)
system.time(predictions <- PredictLogP(structures.file="structures.sdf", threads = 1))
predictions
detach(package:smPredict, unload=TRUE)
library(smPredict)
system.time(predictions <- PredictLogP(structures.file="structures.sdf", threads = 1))
predictions
system.time(predictions <- PredictLogP(structures.file="structures.sdf", error.variance=TRUE, threads = 1))
predictions
predictions$variance
setwd("~/Dropbox/projects/logP/6_comparison_to_other_tools/error_estimation")
load("spline.rda")
predict(spline, c(5,6))
setwd("~/Dropbox/projects/smPredict/testing_package")
detach(package:smPredict, unload=TRUE)
library(smPredict)
system.time(predictions <- PredictLogP(structures.file="structures.sdf", error.variance=TRUE, threads = 1))
predictions$variance
plot(density(predictions$variance))
detach(package:smPredict, unload=TRUE)
library(smPredict)
system.time(predictions <- PredictLogP(structures.file="structures.sdf", error.variance=TRUE, threads = 1))
plot(density(predictions$variance))
predictions[1,]
smLogP <- prediction[1,]$smLogP
smLogP <- predictions[1,]$smLogP
smLogP
p <- predictions[1,]
smLogP <- p$smLogP
variance <- p$variance
x=seq(smLogP-3*variance,smLogP+3*variance,length=400)
A <- (1 - 0)/(1/(sigma*2*pi))*exp(-0.5*(0/sigma)^2)
sigma <- sqrt(p$variance)
x=seq(smLogP-6*sigma,smLogP+6*sigma,length=400)
A <- (1 - 0)/(1/(sigma*2*pi))*exp(-0.5*(0/sigma)^2)
y <- 1 - A*0.98*(1/(sigma*2*pi))*exp(-0.5*(x/sigma)^2)
gaussian <- data.frame(x=x, y=y)
p <- p + geom_line(aes(x = x, y = y), size=1.5, colour = "red", data=gaussian)
gaussian <- data.frame(x=x, y=y)
p <- p + geom_line(aes(x = x, y = y), size=1.5, colour = "red", data=gaussian)
library(ggplot2)
p <- p + geom_line(aes(x = x, y = y), size=1.5, colour = "red", data=gaussian)
p <- ggplot(xlim(min(x), max(x)) + ylim(0,1)
gaussian <- data.frame(x=x, y=y)
p <- ggplot() + xlim(min(x), max(x)) + ylim(0,1)
p <- p + geom_line(aes(x = x, y = y), size=1.5, colour = "red", data=gaussian)
plot(p)
y <- 1 - A*0.98*(1/(sigma*2*pi))*exp(-0.5*(x-smLogP/sigma)^2)
p <- ggplot() + xlim(min(x), max(x)) + ylim(0,1)
gaussian <- data.frame(x=x, y=y)
p <- p + geom_line(aes(x = x, y = y), size=1.5, colour = "red", data=gaussian)
plot(p)
p
predictions[1,]
min(x)
max(x)
y <- A*0.98*(1/(sigma*2*pi))*exp(-0.5*(x-smLogP/sigma)^2)
p <- ggplot() + xlim(min(x), max(x)) + ylim(0,1)
gaussian <- data.frame(x=x, y=y)
p <- p + geom_line(aes(x = x, y = y), size=1.5, colour = "red", data=gaussian)
plot(p)
